{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handed-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developed-metro",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../clean_data/emission_goals.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1ac3e588f256>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Read the csv file into a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0memission_goals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../clean_data/emission_goals.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0memission_goals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../clean_data/emission_goals.csv'"
     ]
    }
   ],
   "source": [
    "# Read the csv file into a pandas DataFrame\n",
    "emission_goals = pd.read_csv('clean_data/emission_goals.csv')\n",
    "emission_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(emission_goals.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = emission_goals[emission_goals[\"country\"].isin([\"Global\", \"US\", \"EU\", \"India\", \"China\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out data by suffix\n",
    "all_energy = selected_df.filter(regex='all_energy$',axis=1).head()\n",
    "# all_energy.drop_suffix('all_energy')\n",
    "# Flip the df\n",
    "all_energyT = all_energy.T\n",
    "all_energyT = all_energyT.reset_index(drop=False)\n",
    "# Rename columns\n",
    "all_energyT = all_energyT.rename(columns={\"index\":\"year\", 99: \"oil\"})\n",
    "# all_energyT.set_index(\"year\", inplace=True)\n",
    "\n",
    "\n",
    "allenergy_final = all_energyT.rename(columns={0:'Global', 1:'US', 2:'EU', 4 :'India', 5:'China'})\n",
    "allenergy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = allenergy_final['year'] \n",
    "\n",
    "col_split1 =[x.split('.') for x in col]\n",
    "split_df1 = pd.DataFrame(col_split1)\n",
    "# us_df_new[['years','extra']] = us_df_new[[x.split('.') for x in (us_df_new['year'])]]\n",
    "split_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df1.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "allenergy_final[['year']]=split_df1.iloc[:,0]\n",
    "allenergy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "allenergy_final['year'] = allenergy_final['year'].astype(int)\n",
    "allenergy_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Trends through plots\n",
    "plt.plot(allenergy_final.year, allenergy_final.Global, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allenergy_final.year, allenergy_final.US, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allenergy_final.year, allenergy_final.EU, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-certification",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allenergy_final.year, allenergy_final.India, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(allenergy_final.year, allenergy_final.China, 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-bubble",
   "metadata": {},
   "source": [
    "### Adjustment for US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most recent trend\n",
    "us_sele = allenergy_final[allenergy_final[\"year\"] > 2017]\n",
    "us_sele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(us_sele.year, us_sele.US, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "X = us_sele.year.values.reshape(-1, 1)\n",
    "y = us_sele.US.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-latitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(renew_X, ln_Y)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we have to transform our min and max values \n",
    "# so they are in the format: array([[ 1.17]])\n",
    "# This is the required format for `model.predict()`\n",
    "\n",
    "x_min = np.array([[X.min()]])\n",
    "x_max = np.array([[X.max()]])\n",
    "print(f\"Min X Value: {x_min}\")\n",
    "print(f\"Max X Value: {x_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the y_min and y_max using model.predict and x_min and x_max\n",
    "# y_min = model.predict(x_min)\n",
    "# y_max = model.predict(x_max)\n",
    "y_min = model.predict(x_min)\n",
    "y_max = model.predict(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot X and y using plt.scatter\n",
    "# Plot the model fit line using [x_min[0], x_max[0]], [y_min[0], y_max[0]]\n",
    "plt.scatter(X, y, c='blue')\n",
    "plt.plot([x_min[0], x_max[0]], [y_min[0], y_max[0]], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_years = [2020, 2030, 2040, 2050]\n",
    "year_df = pd.DataFrame(new_years, columns = ['year'])\n",
    "year_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predict_2020 = model.predict([[2020]])\n",
    "predict_2020 = list(predict_2020[0])\n",
    "predict_2020 = predict_2020[0]\n",
    "\n",
    "predict_2030 = model.predict([[2030]])\n",
    "predict_2030 = list(predict_2030[0])\n",
    "predict_2030 = predict_2030[0]\n",
    "\n",
    "predict_2040 = model.predict([[2040]])\n",
    "predict_2040 = list(predict_2040[0])\n",
    "predict_2040 = predict_2040[0]\n",
    "\n",
    "predict_2050 = model.predict([[2050]])\n",
    "predict_2050 = list(predict_2050[0])\n",
    "predict_2050 = predict_2050[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_values = [predict_2020, predict_2030, predict_2040, predict_2050]\n",
    "data_years = {\"year\":new_years,\n",
    "           \"US\": predict_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_predict_df = pd.DataFrame(data_years, columns=[\"year\", 'US'])\n",
    "us_predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-relations",
   "metadata": {},
   "source": [
    "### Adjustment for EU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most recent trend\n",
    "eu_sele = allenergy_final[allenergy_final[\"year\"] > 2005]\n",
    "eu_sele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-thailand",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(eu_sele.year, eu_sele.EU, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "X = eu_sele.year.values.reshape(-1, 1)\n",
    "y = eu_sele.EU.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "# model.fit(renew_X, ln_Y)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we have to transform our min and max values \n",
    "# so they are in the format: array([[ 1.17]])\n",
    "# This is the required format for `model.predict()`\n",
    "\n",
    "x_min = np.array([[X.min()]])\n",
    "x_max = np.array([[X.max()]])\n",
    "print(f\"Min X Value: {x_min}\")\n",
    "print(f\"Max X Value: {x_max}\")\n",
    "\n",
    "# Calculate the y_min and y_max using model.predict and x_min and x_max\n",
    "# y_min = model.predict(x_min)\n",
    "# y_max = model.predict(x_max)\n",
    "y_min = model.predict(x_min)\n",
    "y_max = model.predict(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-fifteen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot X and y using plt.scatter\n",
    "# Plot the model fit line using [x_min[0], x_max[0]], [y_min[0], y_max[0]]\n",
    "plt.scatter(X, y, c='blue')\n",
    "plt.plot([x_min[0], x_max[0]], [y_min[0], y_max[0]], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predict_2020 = model.predict([[2020]])\n",
    "predict_2020 = list(predict_2020[0])\n",
    "predict_2020 = predict_2020[0]\n",
    "\n",
    "predict_2030 = model.predict([[2030]])\n",
    "predict_2030 = list(predict_2030[0])\n",
    "predict_2030 = predict_2030[0]\n",
    "\n",
    "predict_2040 = model.predict([[2040]])\n",
    "predict_2040 = list(predict_2040[0])\n",
    "predict_2040 = predict_2040[0]\n",
    "\n",
    "predict_2050 = model.predict([[2050]])\n",
    "predict_2050 = list(predict_2050[0])\n",
    "predict_2050 = predict_2050[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_values = [predict_2020, predict_2030, predict_2040, predict_2050]\n",
    "data_years = {\"year\":new_years,\n",
    "           \"EU\": predict_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "eu_predict_df = pd.DataFrame(data_years, columns=[\"year\", 'EU'])\n",
    "eu_predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-atlanta",
   "metadata": {},
   "source": [
    "### Adjustment for India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most recent trend\n",
    "india_sele = allenergy_final[allenergy_final[\"year\"] > 2000]\n",
    "india_sele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(india_sele.year, india_sele.India, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "X = india_sele.year.values.reshape(-1, 1)\n",
    "y = india_sele.India.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(renew_X, ln_Y)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we have to transform our min and max values \n",
    "# so they are in the format: array([[ 1.17]])\n",
    "# This is the required format for `model.predict()`\n",
    "\n",
    "x_min = np.array([[X.min()]])\n",
    "x_max = np.array([[X.max()]])\n",
    "print(f\"Min X Value: {x_min}\")\n",
    "print(f\"Max X Value: {x_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the y_min and y_max using model.predict and x_min and x_max\n",
    "# y_min = model.predict(x_min)\n",
    "# y_max = model.predict(x_max)\n",
    "y_min = model.predict(x_min)\n",
    "y_max = model.predict(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot X and y using plt.scatter\n",
    "# Plot the model fit line using [x_min[0], x_max[0]], [y_min[0], y_max[0]]\n",
    "plt.scatter(X, y, c='blue')\n",
    "plt.plot([x_min[0], x_max[0]], [y_min[0], y_max[0]], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predict_2020 = model.predict([[2020]])\n",
    "predict_2020 = list(predict_2020[0])\n",
    "predict_2020 = predict_2020[0]\n",
    "\n",
    "predict_2030 = model.predict([[2030]])\n",
    "predict_2030 = list(predict_2030[0])\n",
    "predict_2030 = predict_2030[0]\n",
    "\n",
    "predict_2040 = model.predict([[2040]])\n",
    "predict_2040 = list(predict_2040[0])\n",
    "predict_2040 = predict_2040[0]\n",
    "\n",
    "predict_2050 = model.predict([[2050]])\n",
    "predict_2050 = list(predict_2050[0])\n",
    "predict_2050 = predict_2050[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_values = [predict_2020, predict_2030, predict_2040, predict_2050]\n",
    "data_years = {\"year\":new_years,\n",
    "           \"India\": predict_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "india_predict_df = pd.DataFrame(data_years, columns=[\"year\", 'India'])\n",
    "india_predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intended-thirty",
   "metadata": {},
   "source": [
    "### Adjustment for China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select most recent trend\n",
    "china_sele = allenergy_final[allenergy_final[\"year\"] > 2000]\n",
    "china_sele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(china_sele.year, china_sele.China, 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "# Note: Sklearn requires a two-dimensional array of values\n",
    "# so we use reshape to create this\n",
    "\n",
    "X = china_sele.year.values.reshape(-1, 1)\n",
    "y = china_sele.China.values.reshape(-1, 1)\n",
    "\n",
    "print(\"Shape: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LinearRegression model and fit it to the scaled training data\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "# model.fit(renew_X, ln_Y)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we have to transform our min and max values \n",
    "# so they are in the format: array([[ 1.17]])\n",
    "# This is the required format for `model.predict()`\n",
    "\n",
    "x_min = np.array([[X.min()]])\n",
    "x_max = np.array([[X.max()]])\n",
    "print(f\"Min X Value: {x_min}\")\n",
    "print(f\"Max X Value: {x_max}\")\n",
    "\n",
    "# Calculate the y_min and y_max using model.predict and x_min and x_max\n",
    "# y_min = model.predict(x_min)\n",
    "# y_max = model.predict(x_max)\n",
    "y_min = model.predict(x_min)\n",
    "y_max = model.predict(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot X and y using plt.scatter\n",
    "# Plot the model fit line using [x_min[0], x_max[0]], [y_min[0], y_max[0]]\n",
    "plt.scatter(X, y, c='blue')\n",
    "plt.plot([x_min[0], x_max[0]], [y_min[0], y_max[0]], c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predict_2020 = model.predict([[2020]])\n",
    "predict_2020 = list(predict_2020[0])\n",
    "predict_2020 = predict_2020[0]\n",
    "\n",
    "predict_2030 = model.predict([[2030]])\n",
    "predict_2030 = list(predict_2030[0])\n",
    "predict_2030 = predict_2030[0]\n",
    "\n",
    "predict_2040 = model.predict([[2040]])\n",
    "predict_2040 = list(predict_2040[0])\n",
    "predict_2040 = predict_2040[0]\n",
    "\n",
    "predict_2050 = model.predict([[2050]])\n",
    "predict_2050 = list(predict_2050[0])\n",
    "predict_2050 = predict_2050[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_values = [predict_2020, predict_2030, predict_2040, predict_2050]\n",
    "data_years = {\"year\":new_years,\n",
    "           \"China\": predict_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "china_predict_df = pd.DataFrame(data_years, columns=[\"year\", 'China'])\n",
    "china_predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-department",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the predictions\n",
    "us_predict_df.to_csv('us_allenergy_adjust_recent.csv', encoding='utf-8')\n",
    "eu_predict_df.to_csv('eu_allenergy_adjust_recent.csv', encoding='utf-8')\n",
    "india_predict_df.to_csv('india_allenergy_adjust_recent.csv', encoding='utf-8')\n",
    "china_predict_df.to_csv('china_allenergy_adjust_recent.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-experiment",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
